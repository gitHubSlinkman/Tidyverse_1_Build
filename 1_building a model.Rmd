---
title: "1 Build a model"
author: "Craig W. Slinkman"
date: "3/7/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Build a model

## Introduction

This is my solution to the tidymodel tutorial found  [here](https://www.tidymodels.org/start/models/).  My solution may differ somewhat from the tutorial solution because of my own R coding style. 

## Build a model

### Packages: broom and parsnip

* INTRODUCTION
* THE SEA URCHINS DATA
* BUILD AND FIT A MODEL
* USE A MODEL TO PREDICT
* MODEL WITH A DIFFERENT ENGINE
* WHY DOES IT WORK THAT WAY?
* SESSION INFORMATION

### INTRODUCTION

How do you create a statistical model using tidymodels? In this article, we will walk you through the steps. We start with data for modeling, learn how to specify and train models with different engines using the parsnip package, and understand why these functions are designed this way.

To use code in this article, you will need to install the following packages: **broom.mixed**, **dotwhisker**, **readr**, **rstanarm**, and **tidymodels**.  To use code in this article, you will need to install the following packages: broom.mixed, dotwhisker, readr, rstanarm, and tidymodels.

We load these packages below:

```{r}
library(tidymodels)  # for the parsnip package, along with the rest of tidymodels

# Helper packages
library(readr)       # for importing data
library(broom.mixed) # for converting bayesian models to tidy tibbles
library(dotwhisker)  # for visualizing regression results
library(cowplot)     # For cowplot graphics theme.
```

### THE SEA URCHINS DATA

Let’s use the data from [Constable (1993)](https://link.springer.com/article/10.1007/BF00349318)  to explore how three different feeding regimes affect the size of sea urchins over time. The initial size of the sea urchins at the beginning of the experiment probably affects how big they grow as they are fed.

To start, lets read our urchins data into R, which we’ll do by providing readr::read_csv() with a url where our CSV data is located (“https://tidymodels.org/start/models/urchins.csv”):

```{r}
# Data were assembled for a tutorial
# at https://www.flutterbys.com.au/stats/tut/tut7.5a.html
#
# Remark:  In this code chunk we
#  1. Read remotely read the data form the url using the rear_csv() function
#     in the package readr which is automatically by the package tidymodels.
#   2.Change the names to be a little more descriptive. 
#   3. Convert the character variable food_regime to a factor.

urchins <-
  read_csv("https://tidymodels.org/start/models/urchins.csv") %>%  

    setNames(c("food_regime", "initial_volume", "width")) %>% 
    mutate(food_regime = factor(food_regime, 
                                levels = c("Initial", "Low", "High")))
```

Let’s take a quick look at the data:

```{r}
urchins            # Display first 10 rows of urchins along with data types
```
 
The urchins data is a tibble. If you are new to tibbles, the best place to start is the tibbles chapter in R for Data Science. For each of the 72 urchins, we know their:

* experimental feeding regime group (food_regime: either Initial, Low, or High),
* size in milliliters at the start of the experiment (initial_volume), and
* suture width at the end of the experiment (width). 

As a first step in modeling, its always a good idea to plot the data  We use 
**ggplot** (loaded by **tidymodels**) to plot the data:

```{r}
ggplot(urchins,
       aes(x = initial_volume, 
           y = width, 
           group = food_regime, 
           col = food_regime)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) +
  scale_color_viridis_d(option = "plasma", end = .7) +
  theme_cowplot()
```


**Remark:** Failure to plot and look is statistical malfeasance.

**Remark:** Note that I use the the function **theme_cowplot()** to make my plots look more professional.

We can see that urchins that were larger in volume at the start of the experiment tended to have wider sutures at the end, but the slopes of the lines look different so this effect may depend on the feeding regime condition.

**Remark:** That is we have interaction between the food regeime and the initial volume.

## Build and fir a model

A standard two-way analysis of variance (ANOVA) model makes sense for this dataset because we have both a continuous predictor and a categorical predictor. Since the slopes appear to be different for at least two of the feeding regimes, lets build a model that allows for two-way interactions. Specifying an R formula with our variables in this way:

```
width ~ initial_volume * food_regime
```
allows our regression model depending on initial volume to have separate slopes and intercepts for each food regime.

For this kind of model, ordinary least squares is a good initial approach. With tidymodels, we start by specifying the functional form of the model that we want using the parsnip package. Since there is a numeric outcome and the model should be linear with slopes and intercepts, the model type is “linear regression”. We can declare this with:

```
linear_reg()                            # Linear model specification
```
That is pretty underwhelming since, on its own, it doesn’t really do much. However, now that the type of model has been specified, a method for fitting or training the model can be stated using the engine. The engine value is often a mash-up of the software that can be used to fit or train the model as well as the estimation method. For example, to use ordinary least squares, we can set the engine to be ##lm##:

```{r}
linear_reg() %>%             # Linear Regression Model Specification (regression)
  set_engine("lm")           # Computational engine lm (linear model) 
```
 [linear_reg()](https://parsnip.tidymodels.org/reference/linear_reg.html) defines a model that can predict numeric values from predictors using a linear function. This function can fit regression models.

The [documentation page](https://parsnip.tidymodels.org/reference/linear_reg.html) for **linear_reg()** lists the possible engines. We’ll save this model object as
**lm_mod**.  

```{r}
lm_mod <-
  linear_reg() %>%             # Linear Regression Model Specification (regression)
  set_engine("lm")             #  Computational engine lm (linear model)
```

From here, the model can be estimated or trained using the **fit()** function:

```{r}
lm_fit <- 
  lm_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)
lm_fit
```

 Perhaps our analysis requires a description of the model parameter estimates and their statistical properties. Although the **summary()** function for **lm** objects can provide that, it gives the results back in an unwieldy format. Many models have a **tidy()** method that provides the summary results in a more predictable and useful format (e.g. a data frame with standard column names): 
 
```{r}
tidy(lm_fit)  
```

This kind of output can be used to generate a dot-and-whisker plot of our regression results using the dotwhisker package:

```{r}
tidy(lm_fit) %>% 
  dwplot(dot_args = list(size = 2, color = "black"),
         whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, 
                            colour = "grey50", 
                            linetype = 2)) +
    theme_cowplot()
```

***Remark:*** This allows to vizualization what predictor variablkes are likely to be important predictors of the response variable.

## Build and fir a model

This fitted object lm_fit has the lm model output built-in, which you can access with lm_fit$fit, but there are some benefits to using the fitted parsnip model object when it comes to predicting.

Suppose that, for a publication, it would be particularly interesting to make a plot of the mean body size for urchins that started the experiment with an initial volume of 20ml. To create such a graph, we start with some new example data that we will make predictions for, to show in our graph:

```{r}
new_points <- expand.grid(initial_volume = 20, 
                          food_regime = c("Initial", "Low", "High"))
new_points
```  
 
To get our predicted results, we can use the predict() function to find the mean values at 20ml.

It is also important to communicate the variability, so we also need to find the predicted confidence intervals. If we had used the **lm()** to fit the model directly, a few minutes of reading the documentation page for the function **predict**.lm() would explain how to do this. However, if we decide to use a different model to estimate urchin size (spoiler: we will!), it is likely that a completely different syntax would be required.

Instead, with **tidymodels**, the types of predicted values are standardized so that we can use the same syntax to get these values.

First, let’s generate the mean body width values:

```{r}
new_points <- expand.grid(initial_volume = 20,    # Define predictor variable
                          food_regime =           # values to be used for 
                            c("Initial",          # predictions.
                              "Low", 
                              "High"))
new_points                                        # Verify prediction data.
```  

It is also important to communicate the variability, so we also need to find the predicted confidence intervals. If we had used lm() to fit the model directly, a few minutes of reading the documentation page for predict.lm() would explain how to do this. However, if we decide to use a different model to estimate urchin size (spoiler: we will!), it is likely that a completely different syntax would be required.  

```{r}
conf_int_pred <-                   # Confidence intervals for predictions
  predict(lm_fit, 
  new_data = new_points, 
  type = "conf_int")
  
  conf_int_pred                    # View cinidence intervals                         
```




 
